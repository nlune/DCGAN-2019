{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# hyperparameters\n",
    "batch_size=32\n",
    "z_dim = 100 # random noise vector dimension \n",
    "\n",
    "beta1=0.5 # β1 Adam training param\n",
    "lmda = 0.003 # λ ratio for prior loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data TODO\n",
    "image_shape = (64, 64, 3)\n",
    "\n",
    "z = tf.placeholder(tf.float32, shape=(batch_size, z_dim)) # vec from uniform distr. [-1, 1]\n",
    "discriminator_input = tf.placeholder(tf.float32, shape=(batch_size*2, 64, 64, 3))\n",
    "\n",
    "mask = tf.placeholder(tf.float32, shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer functions\n",
    "def feed_forward_layer(name, x, hidden_n, activation_fn, normalize, stddev=0.02):\n",
    "        with tf.variable_scope(name):\n",
    "            initializer = tf.random_normal_initializer(stddev)\n",
    "            weights = tf.get_variable(\"weights\", [x.shape[1], hidden_n], tf.float32, initializer)\n",
    "            biases = tf.get_variable(\"biases\", [hidden_n], tf.float32, tf.zeros_initializer())\n",
    "\n",
    "            drive = tf.matmul(x, weights) + biases\n",
    "            if normalize:\n",
    "                drive = batch_norm(drive, [0])\n",
    "\n",
    "            if activation_fn == 'none':\n",
    "                return drive\n",
    "            else:\n",
    "                return activation_fn(drive)\n",
    "\n",
    "\n",
    "def conv_layer(name, x, kernels_n, kernel_size, stride_size, activation_fn, normalize, stddev=0.02):\n",
    "    with tf.variable_scope(name):\n",
    "        initializer = tf.random_normal_initializer(stddev)\n",
    "        kernels = tf.get_variable(\"kernels\", [kernel_size, kernel_size, x.shape[-1], kernels_n], tf.float32, initializer)\n",
    "        biases = tf.get_variable(\"biases\", [kernels_n], tf.float32, tf.zeros_initializer())\n",
    "\n",
    "        drive = tf.nn.conv2d(x, kernels, strides = [1, stride_size, stride_size, 1], padding = \"SAME\") + biases\n",
    "        if normalize:\n",
    "            drive = batch_norm(drive, [0,1,2])\n",
    "    \n",
    "        return activation_fn(drive)\n",
    "\n",
    "\n",
    "def deconv_layer(name, x, target_shape, kernel_size, stride_size, activation_fn, normalize, stddev=0.02):\n",
    "    with tf.variable_scope(name):\n",
    "        initializer = tf.random_normal_initializer(stddev)\n",
    "        kernels = tf.get_variable(\"kernels\", [kernel_size, kernel_size, target_shape[-1], x.shape[-1]], tf.float32, initializer)\n",
    "        biases = tf.get_variable(\"biases\", [target_shape[-1]], tf.float32, tf.zeros_initializer())\n",
    "\n",
    "        drive = tf.nn.conv2d_transpose(x, kernels, target_shape, strides = [1, stride_size, stride_size, 1], padding = \"SAME\") + biases\n",
    "        if normalize:\n",
    "            drive = batch_norm(drive, [0,1,2])\n",
    "\n",
    "        return activation_fn(drive)\n",
    "\n",
    "\n",
    "def flatten(x):\n",
    "    flat_length = int(np.prod(x.shape[1:]))\n",
    "    return tf.reshape(x, [-1, flat_length])\n",
    "\n",
    "\n",
    "def batch_norm(x, axes):\n",
    "    mean, var = tf.nn.moments(x, axes = axes)\n",
    "    offset_initializer = tf.constant_initializer(0.0)\n",
    "    offset = tf.get_variable(\"offset\", [x.shape[-1]], tf.float32, offset_initializer)\n",
    "    scale_initializer = tf.constant_initializer(1.0)\n",
    "    scale = tf.get_variable(\"scale\", [x.shape[-1]], tf.float32, scale_initializer)\n",
    "    return tf.nn.batch_normalization(x, mean, var, offset, scale, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL \n",
    "\n",
    "# Generator\n",
    "with tf.variable_scope(\"Generator\", reuse=tf.AUTO_REUSE):\n",
    "        out = feed_forward_layer(name = \"layer_1\",\n",
    "                                 x= z, \n",
    "                                 activation_fn=tf.nn.relu, \n",
    "                                 hidden_n=8192,\n",
    "                                 normalize=True)\n",
    "        l1_out = tf.reshape(out, [batch_size,4,4,512])\n",
    "\n",
    "        l2_out = deconv_layer(name= \"layer_2\",\n",
    "                              x=l1_out, \n",
    "                              kernel_size=5, \n",
    "                              stride_size=2,\n",
    "                              activation_fn=tf.nn.relu, \n",
    "                              normalize=True,\n",
    "                              target_shape=[batch_size,8,8,256])\n",
    "\n",
    "        l3_out = deconv_layer(name= \"layer_3\",\n",
    "                              x=l2_out, \n",
    "                              kernel_size=5, \n",
    "                              stride_size=2,\n",
    "                              activation_fn=tf.nn.relu, \n",
    "                              normalize=True,\n",
    "                              target_shape=[batch_size,16,16,128])\n",
    "        \n",
    "        l4_out = deconv_layer(name= \"layer_4\",\n",
    "                              x=l3_out, \n",
    "                              kernel_size=5, \n",
    "                              stride_size=2,\n",
    "                              activation_fn=tf.nn.relu, \n",
    "                              normalize=True,\n",
    "                              target_shape=[batch_size,32,32,64])\n",
    "        \n",
    "        l5_out = deconv_layer(name= \"g_out\",\n",
    "                              x= l4_out, \n",
    "                              kernel_size=5, \n",
    "                              stride_size=2,\n",
    "                              activation_fn=tf.nn.relu, \n",
    "                              normalize=True,\n",
    "                              target_shape=[batch_size,64,64,3])\n",
    "        \n",
    "        \n",
    "# Discriminator\n",
    "with tf.variable_scope(\"Discriminator\", reuse=tf.AUTO_REUSE):\n",
    "    l1 = conv_layer(name= \"layer_1\", \n",
    "                        x = discriminator_input,\n",
    "                        activation_fn= tf.nn.leaky_relu, \n",
    "                        kernel_size=5, \n",
    "                        kernels_n=64,\n",
    "                        stride_size = 2,  \n",
    "                        normalize=True)\n",
    "    \n",
    "    l2 = conv_layer(name= \"layer_2\", \n",
    "                        x = l1,\n",
    "                        activation_fn= tf.nn.leaky_relu, \n",
    "                        kernel_size=5, \n",
    "                        kernels_n=128,\n",
    "                        stride_size = 2,  \n",
    "                        normalize=True)\n",
    "    \n",
    "    l3 = conv_layer(name= \"layer_3\", \n",
    "                        x = l2,\n",
    "                        activation_fn= tf.nn.leaky_relu, \n",
    "                        kernel_size=5, \n",
    "                        kernels_n=256,\n",
    "                        stride_size = 2,  \n",
    "                        normalize=True)\n",
    "    \n",
    "    l4 = conv_layer(name= \"layer_4\", \n",
    "                        x = l3,\n",
    "                        activation_fn= tf.nn.leaky_relu, \n",
    "                        kernel_size=5, \n",
    "                        kernels_n=512,\n",
    "                        stride_size = 2,  \n",
    "                        normalize=True)\n",
    "    l4_reshaped = flatten(l4)\n",
    "    out = feed_forward_layer(name=\"d_out\", \n",
    "                             x= l4_reshaped,\n",
    "                             activation_fn= 'none', \n",
    "                             hidden_n=1, \n",
    "                             normalize=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ann]",
   "language": "python",
   "name": "conda-env-ann-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
